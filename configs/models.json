{
    "gpt-4": {
        "name": "gpt-4",
        "max_tokens": 8192,
        "tokens_per_minute": 10000,
        "request_per_minute": 200,
        "request_per_day": 200,
        "input_price": 0.03,
        "output_price": 0.06,
        "description": "More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Will be updated with our latest model iteration 2 weeks after it is released."
    },
    "gpt-4-32k": {
        "name": "gpt-4-32k",
        "max_tokens": 32768,
        "tokens_per_minute": 250000,
        "request_per_minute": 200,
        "request_per_day": 200,
        "input_price": 0.06,
        "output_price": 0.12,
        "description": "Same capabilities as the standard gpt-4 mode but with 4x the context length. Will be updated with our latest model iteration."
    },
    "gpt-3.5-turbo": {
        "name": "gpt-3.5-turbo",
        "max_tokens": 4097,
        "tokens_per_minute": 90000,
        "request_per_minute": 3500,
        "request_per_day": 3500,
        "input_price": 0.0015,
        "output_price": 0.002,
        "description": "Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. Will be updated with our latest model iteration 2 weeks after it is released."
    },
    "gpt-3.5-turbo-16k": {
        "name": "gpt-3.5-turbo-16k",
        "max_tokens": 16385,
        "tokens_per_minute": 180000,
        "request_per_minute": 3500,
        "request_per_day": 3500,
        "input_price": 0.003,
        "output_price": 0.004,
        "description": "Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context."
    }
}